{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9f4107-83a1-4cf6-8340-9f9454b57eae",
   "metadata": {},
   "source": [
    "# What's Inside a Data Query Engine  \n",
    "## *Building one from Scratch*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7f6a2-f89c-4a55-bdd6-6d16dc6c7a4e",
   "metadata": {},
   "source": [
    "## Part 2: Just A Tad More Detail \n",
    "  \n",
    "![What's Inside a Data Query Engine](./images/dataengine05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21bef00-086e-44fd-b516-01016a08432d",
   "metadata": {},
   "source": [
    "### <font color='green'>__Support for Google Colab__  </font>  \n",
    "    \n",
    "open this notebook in Colab using the following button:  \n",
    "  \n",
    "<a href=\"https://colab.research.google.com/github/shauryashaurya/learn-data-munging/blob/main/00-Python-Collections/01.03%20Fun%20with%20Functools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \n",
    "\n",
    "  \n",
    "<font color='green'>uncomment and execute the cell below to setup and run this notebook on Google Colab.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cbba6f93-2b10-45bf-9975-a41d30ffd219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SETUP FOR COLAB: select all the lines below and uncomment (CTRL+/ on windows)\n",
    "# # Let's download and unzip the Small MovieLens Dataset\n",
    "# ! mkdir ./../data\n",
    "# ! wget -q https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# ! unzip ./ml-latest-small.zip -d ./../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868129c9-cedd-4513-997b-53f9427b6f1a",
   "metadata": {},
   "source": [
    "### Get the _Small_ MovieLens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afc9a9-31b8-483d-89c1-699867c8700b",
   "metadata": {},
   "source": [
    "We'll use the [small MovieLens dataset](https://grouplens.org/datasets/movielens/#:~:text=Small%3A%20100%2C000%20ratings%20and%203%2C600%20tag%20applications) here.\n",
    "\n",
    "Download it and unzip to the data folder under the name `ml-latest-small`.\n",
    "\n",
    "This dataset expands to about 3.2 MB on your local disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4a045b14-f578-47ad-9972-a3f5aaba0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalocation = \"./data/ml-latest-small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0428c276-5ef7-4bde-addf-3bb79337783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify file names\n",
    "file_path_movies = datalocation + \"movies.csv\"\n",
    "file_path_links = datalocation + \"links.csv\"\n",
    "file_path_ratings = datalocation + \"ratings.csv\"\n",
    "file_path_tags = datalocation + \"tags.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a2d08-d779-42a4-bc7d-6ee820d6c5fd",
   "metadata": {},
   "source": [
    "# Here's what our data engine should be able to do  \n",
    "* Load the data into the memory and capture some metadata (things like column names, data types etc.)  \n",
    "* Get a query, a SELECT (xxx) FROM (xxx) WHERE (XXX)  \n",
    "* Parse the query to make sense of it  \n",
    "* Highlight if there are any errors  \n",
    "* Build a query plan  \n",
    "* By looking at the plan and metadata, optimize the query futher  \n",
    "* Execute the query  \n",
    "* Show the results  \n",
    "* Show the cost of running the query  \n",
    "  \n",
    "  \n",
    "_The full set of notebooks also covers JOINs and nested queries, but we are going to treat them as intermediate to advanced cases - since they may distract us from the goal of just being able to understand how data engines work._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389b097-db0c-49cc-8455-80fbd988ef35",
   "metadata": {},
   "source": [
    "We'll directly use the [CSV module](https://docs.python.org/3/library/csv.html) here just to keep our focus on the data engine itself and not get distracted by the intricacies of loading a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be49771-5b2d-4c28-9afb-f7929a858105",
   "metadata": {},
   "source": [
    "# SQL Parser  \n",
    "  \n",
    "converts SQL queries into a structured Abstract Syntax Tree (AST). \n",
    "AST is a tree representation of the syntactic structure of the SQL code.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4de8e88c-30aa-4ff5-aa64-d563326d35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from typing import List, NamedTuple\n",
    "from enum import Enum, auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e5e29-906d-4a89-8187-3f7f7d8e3bd5",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe00b05-0a2e-4c44-8b7a-b1da72620589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenType(Enum):\n",
    "\tSELECT = auto()\n",
    "\tASTERISK = auto()\n",
    "\tFROM = auto()\n",
    "\tWHERE = auto()\n",
    "\tJOIN = auto()\n",
    "\tON = auto()\n",
    "\tORDER = auto()\n",
    "\tBY = auto()\n",
    "\tGROUP = auto()\n",
    "\tHAVING = auto()\n",
    "\tINSERT = auto()\n",
    "\tUPDATE = auto()\n",
    "\tDELETE = auto()\n",
    "\tIDENTIFIER = auto()\n",
    "\tSTRING = auto()\n",
    "\tNUMBER = auto()\n",
    "\tOPERATOR = auto()\n",
    "\tPUNCTUATION = auto() # ignoring punctuation could be problematic, it's better to support proper COMMA, SEMICOLON etc.\n",
    "\tWHITESPACE = auto()  # so we can ignore it in further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b48b1d0-ff43-484c-9e82-22d4dd9e5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for quick keyword lookup\n",
    "SQL_KEYWORDS = {\n",
    "\t'SELECT': TokenType.SELECT,\n",
    "\t'FROM': TokenType.FROM,\n",
    "\t'WHERE': TokenType.WHERE,\n",
    "\t'JOIN': TokenType.JOIN,\n",
    "\t'ON': TokenType.ON,\n",
    "\t'ORDER': TokenType.ORDER,\n",
    "\t'BY': TokenType.BY,\n",
    "\t'GROUP': TokenType.GROUP,\n",
    "\t'HAVING': TokenType.HAVING,\n",
    "\t'INSERT': TokenType.INSERT,\n",
    "\t'UPDATE': TokenType.UPDATE,\n",
    "\t'DELETE': TokenType.DELETE,\n",
    "\t'ASTERISK': TokenType.ASTERISK\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691aad7e-9ab1-4e14-be9c-6a7eaaca0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sql):\n",
    "\ttoken_patterns = r'''\n",
    "\t\t('[^']*'|\"[^\"]*\")\t\t\t  # String literals\n",
    "\t  | (<=|>=|<>|!=|<|>|=)\t\t\t  # Comparison operators\n",
    "\t  | (\\d+\\.\\d*|\\.\\d+|\\d+)\t\t  # Numeric values\n",
    "\t  | ([,;()])\t\t\t\t\t  # Punctuation\n",
    "\t  | (\\b[a-zA-Z_][a-zA-Z0-9_]*\\b)  # Identifiers or SQL keywords\n",
    "\t  | (\\s+)\t\t\t\t\t\t  # Whitespace\n",
    "\t'''\n",
    "\ttoken_regex = re.compile(token_patterns, re.VERBOSE) #VERBOSE allows for multiline regex with comments \n",
    "\tfor match in token_regex.finditer(sql):\n",
    "\t\ttoken = match.group(0)\n",
    "\t\tif token.isspace():\n",
    "\t\t\tyield (token, TokenType.WHITESPACE)\n",
    "\t\telif token in (',', ';', '(', ')'):\n",
    "\t\t\tyield (token, TokenType.PUNCTUATION)\n",
    "\t\telif token in ('*'):\n",
    "\t\t\tyield (token, TokenType.ASTERISK)\n",
    "\t\telif token.upper() in SQL_KEYWORDS:\n",
    "\t\t\tyield (token.upper(), SQL_KEYWORDS[token.upper()])\n",
    "\t\telif re.match(r'^[\\'\"].*[\\'\"]$', token):\n",
    "\t\t\tyield (token, TokenType.STRING)\n",
    "\t\telif re.match(r'^\\d+(\\.\\d+)?$', token):\n",
    "\t\t\tyield (token, TokenType.NUMBER)\n",
    "\t\telif re.match(r'<=|>=|<>|!=|<|>|=$', token):\n",
    "\t\t\tyield (token, TokenType.OPERATOR)\n",
    "\t\telse:\n",
    "\t\t\tyield (token, TokenType.IDENTIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb9ad6b1-aa48-4c51-95b8-84ffa93a7648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SELECT', <TokenType.SELECT: 1>), (' ', <TokenType.WHITESPACE: 19>), ('name', <TokenType.IDENTIFIER: 14>), (',', <TokenType.PUNCTUATION: 18>), (' ', <TokenType.WHITESPACE: 19>), ('age', <TokenType.IDENTIFIER: 14>), (' ', <TokenType.WHITESPACE: 19>), ('FROM', <TokenType.FROM: 3>), (' ', <TokenType.WHITESPACE: 19>), ('users', <TokenType.IDENTIFIER: 14>), (' ', <TokenType.WHITESPACE: 19>), ('WHERE', <TokenType.WHERE: 4>), (' ', <TokenType.WHITESPACE: 19>), ('age', <TokenType.IDENTIFIER: 14>), (' ', <TokenType.WHITESPACE: 19>), ('>=', <TokenType.OPERATOR: 17>), (' ', <TokenType.WHITESPACE: 19>), ('21', <TokenType.NUMBER: 16>), (' ', <TokenType.WHITESPACE: 19>), ('AND', <TokenType.IDENTIFIER: 14>), (' ', <TokenType.WHITESPACE: 19>), ('status', <TokenType.IDENTIFIER: 14>), (' ', <TokenType.WHITESPACE: 19>), ('=', <TokenType.OPERATOR: 17>), (' ', <TokenType.WHITESPACE: 19>), (\"'active'\", <TokenType.STRING: 15>), (' ', <TokenType.WHITESPACE: 19>), ('ORDER', <TokenType.ORDER: 7>), (' ', <TokenType.WHITESPACE: 19>), ('BY', <TokenType.BY: 8>), (' ', <TokenType.WHITESPACE: 19>), ('age', <TokenType.IDENTIFIER: 14>), (' ', <TokenType.WHITESPACE: 19>), ('DESC', <TokenType.IDENTIFIER: 14>), (';', <TokenType.PUNCTUATION: 18>)]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "sql_query_test_01 = \"SELECT name, age FROM users WHERE age >= 21 AND status = 'active' ORDER BY age DESC;\"\n",
    "t = tokenize(sql_query_test_01)\n",
    "print(list(t))\n",
    "# print(next(t,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718944e3-0a01-42d3-9252-75541c281666",
   "metadata": {},
   "source": [
    "## AST Node Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5141020d-53b1-4c47-949c-50fc46ddf85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTNode:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6752a17-ea28-49fd-a6b1-2aa3e255b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectStatement(ASTNode):\n",
    "\tdef __init__(self, columns, table_name, where_clause=None):\n",
    "\t\tself.columns = columns  # List of column names or '*'\n",
    "\t\tself.table_name = table_name  # Name of the table\n",
    "\t\tself.where_clause = where_clause  # WhereClause node or None\n",
    "\t\tprint(\"SelectStatement: this Select Statement has \\nColumns: \",str(list(self.columns)),\"\\nTable: \",str(self.table_name),\"\\nWHERE CLAUSE: \", str(self.where_clause))\n",
    "\t\t\n",
    "\t# def __repr__(self):\n",
    "\t\t# return \"Select Statement has \\nColumns: \"+str(list(self.columns)),\"\\nTable: \"+str(self.table_name)+\"and WHERE CLAUSE: \"+ str(self.where_clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04ea9efe-b544-41a1-8260-31ebb7264348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhereClause(ASTNode):\n",
    "    def __init__(self, condition):\n",
    "        self.condition = condition  # This could be a more complex structure in a full implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d76103-fd3e-4956-928e-5e7be79b3908",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "025da134-613e-46cc-b7fb-d5389d30ff56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wish this was smaller\n",
    "class Parser:\n",
    "\tdef __init__(self, tokens):\n",
    "\t\tself.tokens = tokens\n",
    "\t\tself.current_token = None\n",
    "\t\tself.next_token = None\n",
    "\t\tself._next_token()\n",
    "\n",
    "\tdef _next_token(self):\n",
    "\t\t\"\"\"Advance to the next token.\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\t# print(\"Parse: _next_token: self.current_token = \",self.current_token)\n",
    "\t\t\t# print(\"Parse: _next_token: self.next_token = \",self.next_token)\n",
    "\t\t\t\n",
    "\t\t\tself.current_token = self.next_token\n",
    "\t\t\tself.next_token = next(self.tokens, None)\n",
    "\t\texcept StopIteration:\n",
    "\t\t\tself.current_token = None\n",
    "\n",
    "\tdef parse(self):\n",
    "\t\t\"\"\"Parse the tokens into an AST.\"\"\"\n",
    "\t\tif (self.current_token == None) and (self.next_token != None):\n",
    "\t\t\tself._next_token()\n",
    "\t\t# \n",
    "\t\tif self.current_token[1] != TokenType.SELECT:\n",
    "\t\t\traise SyntaxError(\"Query must start with SELECT\")\n",
    "\t\tself._next_token()\n",
    "\n",
    "\t\tcolumns = self._parse_columns()\n",
    "\n",
    "\t\tprint(\"Parse: parse: columns = \",columns)\n",
    "\n",
    "\t\t# skip whitespace\n",
    "\t\tif self.current_token[1] == TokenType.WHITESPACE:\n",
    "\t\t\twhile self.current_token[1] == TokenType.WHITESPACE:\n",
    "\t\t\t\tself._next_token()\n",
    "\n",
    "\t\tif self.current_token[1] != TokenType.FROM:\n",
    "\t\t\traise SyntaxError(\"Expected FROM after column list\")\n",
    "\t\tself._next_token()\n",
    "\n",
    "\t\t# print(\"Parse:parse: Now parsing table names: self.current_token = \",self.current_token) \n",
    "\n",
    "\t\ttable_name = self._parse_table_name()\n",
    "\n",
    "\t\tprint(\"Parse: parse: table_name = \",table_name)\n",
    "\n",
    "\t\twhere_clause = None\n",
    "\t\tif self.current_token[1] == TokenType.WHERE:\n",
    "\t\t\tself._next_token()\n",
    "\t\t\twhere_clause = self._parse_where_clause()\n",
    "\n",
    "\t\tprint(\"Parse:parse: where_clause = \", where_clause)\n",
    "\n",
    "\t\treturn SelectStatement(columns, table_name, where_clause)\n",
    "\n",
    "\tdef _parse_columns(self):\n",
    "\t\t\"\"\"Parse the columns part of the SELECT statement.\"\"\"\n",
    "\t\tcolumns = []\n",
    "\n",
    "\t\t# skip whitespace\n",
    "\t\twhile self.current_token[1] == TokenType.WHITESPACE:\n",
    "\t\t\t# print(\"Parse: _parse_columns: ignoring whitespace\")\n",
    "\t\t\t# print(\"Parse: _parse_columns: self.current_token\",self.current_token)\n",
    "\t\t\tself._next_token()\n",
    "\t\t\t# print(\"Parse: _parse_columns: NEW self.current_token\",self.current_token)\n",
    "\t\t\n",
    "\t\t# print(\"Parser: _parse_columns: self.current_token = \",self.current_token[0],self.current_token[1])\n",
    "\t\tif self.current_token[1] == TokenType.ASTERISK:\n",
    "\t\t\tcolumns.append('*')\n",
    "\t\t\tself._next_token()\n",
    "\t\telse:\n",
    "\t\t\twhile True:\n",
    "\t\t\t\t# print(\"Parse: _parse_columns: in WHILE - self.current_token\",self.current_token)\n",
    "\t\t\t\t# skip whitespace or commas\n",
    "\t\t\t\twhile self.current_token[1] == TokenType.WHITESPACE or self.current_token[1] == TokenType.PUNCTUATION:\n",
    "\t\t\t\t\t# print(\"Parse: _parse_columns: in WHILE2 - ignoring whitespace\")\n",
    "\t\t\t\t\t# print(\"Parse: _parse_columns: in WHILE2 - self.current_token\",self.current_token)\n",
    "\t\t\t\t\tself._next_token()\n",
    "\t\t\t\t\t# print(\"Parse: _parse_columns: in WHILE2 - ignoring whitespace - NEW self.current_token\",self.current_token)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# do this till you reach from, we do not support sub-queries in this engine yet.\n",
    "\t\t\t\tif self.current_token[1] == TokenType.FROM:\n",
    "\t\t\t\t\t# print(\"Parse: _parse_columns: found FROM - self.current_token = \",self.current_token)\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tif self.current_token[1] != TokenType.IDENTIFIER:\n",
    "\t\t\t\t\traise SyntaxError(\"Expected column name\")\n",
    "\t\t\t\tprint(\"add \",self.current_token[0],\" to list of columns\")\n",
    "\t\t\t\tcolumns.append(self.current_token[0])\n",
    "\t\t\t\tself._next_token()\n",
    "\t\t\t\t# print(\"Parse: _parse_columns: self.current_token = \",self.current_token)\n",
    "\n",
    "\t\t\t\t# if self.current_token[1] != TokenType.COMMA:\n",
    "\t\t\t\tif self.current_token[1] == TokenType.PUNCTUATION:\n",
    "\t\t\t\t\t# print(\"Parse: _parse_columns: ignoring TokenType.PUNCTUATION\")\n",
    "\t\t\t\t\t# print(\"Parse: _parse_columns: skip punctuation - self.current_token = \",self.current_token)\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t# self._next_token()  # Skip the comma or the whitespace\n",
    "\n",
    "\t\t# print(\"Parse: _parse_columns: self.current_token\",self.current_token)\n",
    "\t\t# print(\"Parse: _parse_columns: columns = \",columns)\n",
    "\t\t\n",
    "\t\treturn columns\n",
    "\n",
    "\tdef _parse_table_name(self):\n",
    "\t\t\"\"\"Parse the table name.\"\"\"\n",
    "\t\t# skip whitespace\n",
    "\t\twhile self.current_token[1] == TokenType.WHITESPACE:\n",
    "\t\t\t# print(\"Parse: _parse_table_name: ignoring whitespace\")\n",
    "\t\t\t# print(\"Parse: _parse_table_name: self.current_token\",self.current_token)\n",
    "\t\t\tself._next_token()\n",
    "\t\t\t# print(\"Parse: _parse_table_name: NEW self.current_token\",self.current_token)\n",
    "\t\tif self.current_token[1] != TokenType.IDENTIFIER:\n",
    "\t\t\traise SyntaxError(\"Expected table name\")\n",
    "\t\ttable_name = self.current_token[0]\n",
    "\t\tself._next_token()\n",
    "\t\treturn table_name\n",
    "\n",
    "\t# TODO\n",
    "\tdef _parse_where_clause(self):\n",
    "\t\t\"\"\"Parse the WHERE clause.\"\"\"\n",
    "\t\t# In a full implementation, this would need to handle complex expressions.\n",
    "\t\t# For simplicity, we'll assume it's just a single condition.\n",
    "\t\tif self.current_token[1] != TokenType.IDENTIFIER and self.current_token[1] != TokenType.WHITESPACE:\n",
    "\t\t\traise SyntaxError(\"Expected condition after WHERE\")\n",
    "\t\t# condition = self.current_token[0]\n",
    "\t\tcondition = None\n",
    "\t\t# self._next_token()\n",
    "\t\treturn WhereClause(condition)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7ed39293-28dd-471b-b9cc-9a8fd28cedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query:\n",
      "\t SELECT name, age FROM users WHERE age > 30\n",
      "add  name  to list of columns\n",
      "add  age  to list of columns\n",
      "Parse: parse: columns =  ['name', 'age']\n",
      "Parse: parse: table_name =  users\n",
      "Parse:parse: where_clause =  None\n",
      "SelectStatement: this Select Statement has \n",
      "Columns:  ['name', 'age'] \n",
      "Table:  users \n",
      "WHERE CLAUSE:  None\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "sql_query_test_02 = \"SELECT name, age FROM users WHERE age > 30\"\n",
    "print(\"SQL Query:\\n\\t\", sql_query_test_02)\n",
    "tokens = tokenize(sql_query_test_02) # separate, as you list(gen) a generator, it's already emitted all values...\n",
    "# print(\"Tokenized:\\n\\t\",list(tokens_check), \" \", tokens_check)\n",
    "parser = Parser(tokens)\n",
    "# print(\"Parser:\\n\\t\",tokens)\n",
    "ast = parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b355676a-5cc4-40c3-8a92-d166e1f66140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SelectStatement object at 0x000001B2908EF6E0>\n"
     ]
    }
   ],
   "source": [
    "# Printing the AST for demonstration\n",
    "print(ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023ef90-8efc-4d51-af84-11a96039bc97",
   "metadata": {},
   "source": [
    "# Storage Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6d950dbf-dd9a-4735-b98e-d8fa161bdecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column:\n",
    "    def __init__(self, name, col_type):\n",
    "        self.name = name\n",
    "        self.col_type = col_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f609fec2-3c53-49d4-8cc7-86b8fa00166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table:\n",
    "\tdef __init__(self, name, columns):\n",
    "\t\tself.name = name\n",
    "\t\tself.columns = {col.name: col for col in columns}\n",
    "\t\tself.data = []\n",
    "\n",
    "\tdef table_scan(self):\n",
    "\t\treturn self.data\n",
    "\n",
    "\tdef insert(self, row):\n",
    "\t\tif set(row.keys()) != set(self.columns.keys()):\n",
    "\t\t\traise ValueError(\"Row does not match table schema\")\n",
    "\t\t# Type checking and conversion can be added here\n",
    "\t\tself.data.append(row)\n",
    "\n",
    "\tdef select(self, columns, limit = -1, where_clause=None):\n",
    "\t\tresult = []\n",
    "\t\tcounter = 0\n",
    "\t\tfor row in self.data:\n",
    "\t\t\tcounter += 1\n",
    "\t\t\tif (counter<=limit or limit == -1) and (where_clause is None or where_clause.evaluate(row)):\n",
    "\t\t\t\tresult_row = {col: row[col] for col in columns}\n",
    "\t\t\t\tresult.append(result_row)\n",
    "\t\t\telse:\n",
    "\t\t\t\tbreak\n",
    "\t\treturn result\n",
    "\n",
    "\t# Todo: Additional methods for update, delete etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8c934b64-4208-4cc9-a55b-702279ee4e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(value, col_type):\n",
    "    \"\"\"\n",
    "    Convert the string value from CSV to the specified data type.\n",
    "    \"\"\"\n",
    "    if col_type == int:\n",
    "        return int(value)\n",
    "    elif col_type == float:\n",
    "        return float(value)\n",
    "    elif col_type == str:\n",
    "        return value\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported column type: {col_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cb867fdb-e283-4973-9e32-5d39c351d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "\tdef __init__(self):\n",
    "\t\tself.tables = {}\n",
    "\n",
    "\tdef create_table(self, name, columns):\n",
    "\t\tself.tables[name] = Table(name, columns)\n",
    "\n",
    "\tdef get_table(self, name):\n",
    "\t\treturn self.tables.get(name)\n",
    "\t\n",
    "\tdef load_csv(self, table_name, file_path, delimiter=',', quotechar='\"', escapechar=None, quoting=csv.QUOTE_MINIMAL):\n",
    "\t\t\"\"\"\n",
    "\t\tLoad data from a CSV file into the specified table with support for different CSV dialects.\n",
    "\t\t\"\"\"\n",
    "\t\tprint(\"Database: load_csv: file_path = \",file_path)\n",
    "\t\ttable = self.get_table(table_name)\n",
    "\t\tif not table:\n",
    "\t\t\traise ValueError(f\"Table {table_name} does not exist\")\n",
    "\n",
    "\t\twith open(file_path, 'r', encoding='utf-8') as file:\n",
    "\t\t\treader = csv.DictReader(file, delimiter=delimiter, quotechar=quotechar, escapechar=escapechar, quoting=quoting)\n",
    "\t\t\tfor row in reader:\n",
    "\t\t\t\tconverted_row = {col: convert_type(row[col], table.columns[col].col_type) for col in row}\n",
    "\t\t\t\ttable.insert(converted_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a08c8899-4b11-450d-a0a4-4ebbd76a1d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'age': 30}]\n"
     ]
    }
   ],
   "source": [
    "# Test this\n",
    "db = Database()\n",
    "db.create_table('users', [Column('name', str), Column('age', int)])\n",
    "db.get_table('users').insert({'name': 'Alice', 'age': 30})\n",
    "print(db.get_table('users').select(['name', 'age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c019ed3a-49b1-41bc-b746-365cae5b7ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: load_csv: file_path =  ./data/ml-latest-small/movies.csv\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "\n",
    "# movieId,title,genres\n",
    "\n",
    "db = Database()\n",
    "db.create_table('movies', [Column('movieId', str), Column('title', str), Column('genres', str)])\n",
    "db.load_csv('movies', file_path_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "836bf743-ce73-435c-bcef-ccc67d4a20c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Toy Story (1995)'},\n",
       " {'title': 'Jumanji (1995)'},\n",
       " {'title': 'Grumpier Old Men (1995)'},\n",
       " {'title': 'Waiting to Exhale (1995)'},\n",
       " {'title': 'Father of the Bride Part II (1995)'},\n",
       " {'title': 'Heat (1995)'},\n",
       " {'title': 'Sabrina (1995)'},\n",
       " {'title': 'Tom and Huck (1995)'},\n",
       " {'title': 'Sudden Death (1995)'},\n",
       " {'title': 'GoldenEye (1995)'}]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lists all the titles\n",
    "# db.get_table('movies').select(['title'])\n",
    "db.get_table('movies').select(['title'], limit = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176169eb-d0e0-4875-ab59-6d25be8e6e8d",
   "metadata": {},
   "source": [
    "# Query Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f1158793-d2c6-4351-82ef-b115b895cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryPlan:\n",
    "\tdef __init__(self):\n",
    "\t\tself.steps = []\n",
    "\n",
    "\tdef add_step(self, step):\n",
    "\t\tself.steps.append(step)\n",
    "\n",
    "\tdef list_steps(self):\n",
    "\t\treturn str(list(self.steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3fca5097-94ab-42de-ab3f-344af6d0d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryPlanner:\n",
    "    def __init__(self, database):\n",
    "        self.database = database\n",
    "\n",
    "    def create_plan(self, ast):\n",
    "        \"\"\"\n",
    "        Create a query execution plan based on the given AST.\n",
    "        \"\"\"\n",
    "        plan = QueryPlan()\n",
    "\n",
    "        # Example: Plan for a simple SELECT query\n",
    "        if isinstance(ast, SelectStatement):\n",
    "            # Step 1: Full Table Scan\n",
    "            plan.add_step(('FullTableScan', ast.table_name))\n",
    "\n",
    "            # Step 2: Filter (WHERE clause)\n",
    "            if ast.where_clause:\n",
    "                plan.add_step(('Filter', ast.where_clause))\n",
    "\n",
    "            # TODO - Step 3: Joins\n",
    "            # for join in ast.joins:\n",
    "            #     plan.add_step(('Join', join.table_name, join.on_condition))\n",
    "\n",
    "            # Additional steps like aggregations can be added here\n",
    "\n",
    "        return plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5567682d-9f45-4119-a7be-cf022c399bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test this sucker\n",
    "planner = QueryPlanner(db)\n",
    "plan = planner.create_plan(ast)  # Assuming 'ast' is an AST from the parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "dc455164-8968-4e36-b272-0d2f5b80f406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FullTableScan', 'movies')]\n"
     ]
    }
   ],
   "source": [
    "print(plan.list_steps())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dcf15-5bdf-4de5-8772-e3fedcdf855e",
   "metadata": {},
   "source": [
    "# Query Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "641a339b-c6a3-4a8d-a282-50c55a62efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryOptimizer:\n",
    "    def __init__(self, database):\n",
    "        self.database = database\n",
    "\n",
    "    def optimize(self, plan):\n",
    "        \"\"\"\n",
    "        Optimize the given query plan.\n",
    "        \"\"\"\n",
    "        optimized_plan = self._apply_predicate_pushdown(plan)\n",
    "        optimized_plan = self._apply_join_reordering(optimized_plan)\n",
    "        return optimized_plan\n",
    "\n",
    "    def _apply_predicate_pushdown(self, plan):\n",
    "        \"\"\"\n",
    "        Apply predicate pushdown optimization.\n",
    "        \"\"\"\n",
    "        # This is a placeholder for predicate pushdown logic.\n",
    "        # In practice, you would modify the plan to move filters closer to the data source.\n",
    "        return plan\n",
    "\n",
    "    def _apply_join_reordering(self, plan):\n",
    "        \"\"\"\n",
    "        Apply join reordering based on a simple heuristic or cost model.\n",
    "        \"\"\"\n",
    "        # This is a placeholder for join reordering logic.\n",
    "        # In practice, you would reorder joins based on size, indexes, or other factors.\n",
    "        return plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fad979f9-efc8-456d-95bb-3e0d0b260388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our dummy optimizer\n",
    "optimizer = QueryOptimizer(db)\n",
    "optimized_plan = optimizer.optimize(plan)  # Assuming 'plan' is from the QueryPlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "90c4a688-b249-4cb6-93e4-9c459a6c4737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FullTableScan', 'movies')]\n"
     ]
    }
   ],
   "source": [
    "print(optimized_plan.list_steps())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3d1de-4af4-4ed7-be9a-42a5380159aa",
   "metadata": {},
   "source": [
    "# The Execution Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a229da4-b48d-4505-8362-9f328d26a732",
   "metadata": {},
   "source": [
    "## Executable Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5a4156fd-40c7-4500-853c-41fa7d120609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic class with a cost function - \n",
    "# because our database will natively provide cost of execution for every query...\n",
    "\n",
    "class BaseOperator:\n",
    "    def __init__(self):\n",
    "        self.rows_processed = 0\n",
    "\n",
    "    def get_cost(self):\n",
    "        return {'rows_processed': self.rows_processed}\n",
    "\n",
    "# Extend this base class in SelectOperator, JoinOperator, GroupByOperator etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2e6a3dea-a426-431a-8d44-02a43ac35100",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableScanOperator(BaseOperator):\n",
    "\tdef __init__(self, table): # Todo: provide a condition filter here to reduce scans -  condition=None)\n",
    "\t\t\n",
    "\t\t# self.db = db\n",
    "\t\t# self.table = self.db.get_table(table)\n",
    "\t\tself.table = table\n",
    "\t\t# self.condition = condition\n",
    "\n",
    "\tdef execute(self):\n",
    "\t\t# table_scan = (row for row in self.table)\n",
    "\t\ttable_scan = self.table.table_scan()\n",
    "\t\tself.rows_processed = len(table_scan)\n",
    "\t\treturn table_scan\n",
    "\n",
    "\tdef get_cost(self):\n",
    "\t\treturn super().get_cost()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "537a7dfd-0e40-4b8e-ac9e-5c78d50fd038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectOperator(BaseOperator):\n",
    "\tdef __init__(self, input_operator, select_columns):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.input_operator = input_operator\n",
    "\t\tself.select_columns = select_columns\n",
    "\t\tself.result_limit = 25\n",
    "\n",
    "\tdef execute(self):\n",
    "\t\tresult = []\n",
    "\t\tfor row in self.input_operator.execute():\n",
    "\t\t\tself.rows_processed += 1\n",
    "\t\t\tif self.rows_processed <= self.result_limit:\n",
    "\t\t\t\tselected_row = {col: row[col] for col in self.select_columns}\n",
    "\t\t\t\tresult.append(selected_row)\n",
    "\t\t\telse:\n",
    "\t\t\t\tbreak\n",
    "\t\treturn result\n",
    "\n",
    "\tdef get_cost(self):\n",
    "\t\treturn super().get_cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9c5a7-3abf-4e27-988b-46225b078613",
   "metadata": {},
   "source": [
    "## Execution Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "982bc3f6-a780-401b-bc2f-f9d2399f84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_executable_plan(plan, database):\n",
    "    \"\"\"\n",
    "    Translate the optimized query plan into executable operations.\n",
    "    \"\"\"\n",
    "    executable_plan = []\n",
    "    for step in plan.steps:\n",
    "        if step[0] == 'FullTableScan':\n",
    "            table_name = step[1]\n",
    "            executable_plan.append(TableScanOperator(database.get_table(table_name)))\n",
    "\n",
    "        elif step[0] == 'Select':\n",
    "            columns = step[1]\n",
    "            input_operator = executable_plan[-1]  # The input is the result of the previous step\n",
    "            executable_plan.append(SelectOperator(input_operator, columns))\n",
    "\n",
    "        # elif step[0] == 'Join':\n",
    "        #     # Assuming step format is ('Join', right_table_name, join_condition)\n",
    "        #     right_table = database.get_table(step[1])\n",
    "        #     join_condition = step[2]\n",
    "        #     left_operator = executable_plan[-1]\n",
    "        #     right_operator = TableScanOperator(right_table)\n",
    "        #     executable_plan.append(JoinOperator(left_operator, right_operator, join_condition))\n",
    "\n",
    "        # Add cases for other types of steps (e.g., 'GroupBy', 'Filter')\n",
    "\n",
    "    return executable_plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca097039-0c2d-437e-8686-c9fe00d72fa8",
   "metadata": {},
   "source": [
    "## Executing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b040b72b-1310-4429-8746-c1b27e85071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(executable_plan):\n",
    "\t\"\"\"\n",
    "\tExecute the query by running each operation in the executable plan.\n",
    "\t\"\"\"\n",
    "\tfor operator in executable_plan:\n",
    "\t\tcost = {}\n",
    "\t\tresult = operator.execute()\n",
    "\t\tcost[str(operator)] = operator.get_cost()\n",
    "\n",
    "\t# The result of the last operation is the result of the entire query\n",
    "\treturn result, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "196bfdcb-1def-45cc-8489-ef6e2afbc71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add  genres  to list of columns\n",
      "Parse: parse: columns =  ['genres']\n",
      "Parse: parse: table_name =  movies\n",
      "Parse:parse: where_clause =  None\n",
      "SelectStatement: this Select Statement has \n",
      "Columns:  ['genres'] \n",
      "Table:  movies \n",
      "WHERE CLAUSE:  None\n",
      "{'<__main__.TableScanOperator object at 0x000001B291BE9670>': {'rows_processed': 9742}}\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "sql_query = \"SELECT genres FROM movies WHERE genres = 'Comedy'\"\n",
    "\n",
    "# Parsing the query to AST\n",
    "tokens = tokenize(sql_query)\n",
    "parser = Parser(iter(tokens))\n",
    "ast = parser.parse()\n",
    "\n",
    "# Creating the query plan\n",
    "planner = QueryPlanner(db)\n",
    "plan = planner.create_plan(ast)\n",
    "\n",
    "# Optimizing the query plan\n",
    "optimizer = QueryOptimizer(db)\n",
    "optimized_plan = optimizer.optimize(plan)\n",
    "\n",
    "# Creating the executable plan\n",
    "executable_plan = create_executable_plan(optimized_plan, db)\n",
    "\n",
    "# Executing the query\n",
    "query_result, query_costs = execute_query(executable_plan)\n",
    "\n",
    "# Output the result\n",
    "print(query_costs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a82fa9-167a-4818-810b-2b0d088e00fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a77dde7-b426-4a2b-a247-547b8c572f7b",
   "metadata": {},
   "source": [
    "Wait, was it this simple?   \n",
    "Yea!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd9648-5a13-446f-a775-76616ace03c1",
   "metadata": {},
   "source": [
    "# Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f9979-d5c1-4fa6-875d-76e2c017ec76",
   "metadata": {},
   "source": [
    "Building a more feature rich data engine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
