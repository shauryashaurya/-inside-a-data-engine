{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9f4107-83a1-4cf6-8340-9f9454b57eae",
   "metadata": {},
   "source": [
    "# What's Inside a Data Query Engine  \n",
    "## *Building one from Scratch*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7f6a2-f89c-4a55-bdd6-6d16dc6c7a4e",
   "metadata": {},
   "source": [
    "## Part 2: Just A Tad More Detail \n",
    "  \n",
    "![What's Inside a Data Query Engine](./images/dataengine05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21bef00-086e-44fd-b516-01016a08432d",
   "metadata": {},
   "source": [
    "### <font color='green'>__Support for Google Colab__  </font>  \n",
    "    \n",
    "open this notebook in Colab using the following button:  \n",
    "  \n",
    "<a href=\"https://colab.research.google.com/github/shauryashaurya/learn-data-munging/blob/main/00-Python-Collections/01.03%20Fun%20with%20Functools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \n",
    "\n",
    "  \n",
    "<font color='green'>uncomment and execute the cell below to setup and run this notebook on Google Colab.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba6f93-2b10-45bf-9975-a41d30ffd219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SETUP FOR COLAB: select all the lines below and uncomment (CTRL+/ on windows)\n",
    "# # Let's download and unzip the Small MovieLens Dataset\n",
    "# ! mkdir ./../data\n",
    "# ! wget -q https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# ! unzip ./ml-latest-small.zip -d ./../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868129c9-cedd-4513-997b-53f9427b6f1a",
   "metadata": {},
   "source": [
    "### Get the _Small_ MovieLens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afc9a9-31b8-483d-89c1-699867c8700b",
   "metadata": {},
   "source": [
    "We'll use the [small MovieLens dataset](https://grouplens.org/datasets/movielens/#:~:text=Small%3A%20100%2C000%20ratings%20and%203%2C600%20tag%20applications) here.\n",
    "\n",
    "Download it and unzip to the data folder under the name `ml-latest-small`.\n",
    "\n",
    "This dataset expands to about 3.2 MB on your local disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a045b14-f578-47ad-9972-a3f5aaba0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalocation = \"./data/ml-latest-small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428c276-5ef7-4bde-addf-3bb79337783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify file names\n",
    "file_path_movies = datalocation + \"movies.csv\"\n",
    "file_path_links = datalocation + \"links.csv\"\n",
    "file_path_ratings = datalocation + \"ratings.csv\"\n",
    "file_path_tags = datalocation + \"tags.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a2d08-d779-42a4-bc7d-6ee820d6c5fd",
   "metadata": {},
   "source": [
    "# Here's what our data engine should be able to do  \n",
    "* Load the data into the memory and capture some metadata (things like column names, data types etc.)  \n",
    "* Get a query, a SELECT (xxx) FROM (xxx) WHERE (XXX)  \n",
    "* Parse the query to make sense of it  \n",
    "* Highlight if there are any errors  \n",
    "* Build a query plan  \n",
    "* By looking at the plan and metadata, optimize the query futher  \n",
    "* Execute the query  \n",
    "* Show the results  \n",
    "* Show the cost of running the query  \n",
    "  \n",
    "  \n",
    "_The full set of notebooks also covers JOINs and nested queries, but we are going to treat them as intermediate to advanced cases - since they may distract us from the goal of just being able to understand how data engines work._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389b097-db0c-49cc-8455-80fbd988ef35",
   "metadata": {},
   "source": [
    "We'll directly use the [CSV module](https://docs.python.org/3/library/csv.html) here just to keep our focus on the data engine itself and not get distracted by the intricacies of loading a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be49771-5b2d-4c28-9afb-f7929a858105",
   "metadata": {},
   "source": [
    "# SQL Parser  \n",
    "  \n",
    "converts SQL queries into a structured Abstract Syntax Tree (AST). \n",
    "AST is a tree representation of the syntactic structure of the SQL code.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de8e88c-30aa-4ff5-aa64-d563326d35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from typing import List, NamedTuple\n",
    "from enum import Enum, auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e5e29-906d-4a89-8187-3f7f7d8e3bd5",
   "metadata": {},
   "source": [
    "## Tokeninze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe00b05-0a2e-4c44-8b7a-b1da72620589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenType(Enum):\n",
    "    SELECT = auto()\n",
    "    FROM = auto()\n",
    "    WHERE = auto()\n",
    "    JOIN = auto()\n",
    "    ON = auto()\n",
    "    ORDER = auto()\n",
    "    BY = auto()\n",
    "    GROUP = auto()\n",
    "    HAVING = auto()\n",
    "    INSERT = auto()\n",
    "    UPDATE = auto()\n",
    "    DELETE = auto()\n",
    "    IDENTIFIER = auto()\n",
    "    STRING = auto()\n",
    "    NUMBER = auto()\n",
    "    OPERATOR = auto()\n",
    "    PUNCTUATION = auto()\n",
    "    WHITESPACE = auto()  # so we can ignore it in further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48882a-088e-4a84-bc06-f3dc6cbe891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a dictionary for quick keyword lookup\n",
    "# SQL_KEYWORDS = {\n",
    "#     'SELECT': TokenType.KEYWORD,\n",
    "#     'FROM': TokenType.KEYWORD,\n",
    "#     'WHERE': TokenType.KEYWORD,\n",
    "#     'JOIN': TokenType.KEYWORD,\n",
    "#     'ON': TokenType.KEYWORD,\n",
    "#     'ORDER': TokenType.KEYWORD,\n",
    "#     'BY': TokenType.KEYWORD,\n",
    "#     'GROUP': TokenType.KEYWORD,\n",
    "#     'HAVING': TokenType.KEYWORD,\n",
    "#     'INSERT': TokenType.KEYWORD,\n",
    "#     'UPDATE': TokenType.KEYWORD,\n",
    "#     'DELETE': TokenType.KEYWORD\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48b1d0-ff43-484c-9e82-22d4dd9e5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for quick keyword lookup\n",
    "SQL_KEYWORDS = {\n",
    "\t'SELECT': TokenType.SELECT,\n",
    "\t'FROM': TokenType.FROM,\n",
    "\t'WHERE': TokenType.WHERE,\n",
    "\t'JOIN': TokenType.JOIN,\n",
    "\t'ON': TokenType.ON,\n",
    "\t'ORDER': TokenType.ORDER,\n",
    "\t'BY': TokenType.BY,\n",
    "\t'GROUP': TokenType.GROUP,\n",
    "\t'HAVING': TokenType.HAVING,\n",
    "\t'INSERT': TokenType.INSERT,\n",
    "\t'UPDATE': TokenType.UPDATE,\n",
    "\t'DELETE': TokenType.DELETE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691aad7e-9ab1-4e14-be9c-6a7eaaca0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sql):\n",
    "    token_patterns = r'''\n",
    "        ('[^']*'|\"[^\"]*\")              # String literals\n",
    "      | (<=|>=|<>|!=|<|>|=)            # Comparison operators\n",
    "      | (\\d+\\.\\d*|\\.\\d+|\\d+)           # Numeric values\n",
    "      | ([,;()])                       # Punctuation\n",
    "      | (\\b[a-zA-Z_][a-zA-Z0-9_]*\\b)   # Identifiers or SQL keywords\n",
    "      | (\\s+)                          # Whitespace\n",
    "    '''\n",
    "    token_regex = re.compile(token_patterns, re.VERBOSE) #VERBOSE allows for multiline regex with comments \n",
    "    for match in token_regex.finditer(sql):\n",
    "        token = match.group(0)\n",
    "        if token.isspace():\n",
    "            yield (token, TokenType.WHITESPACE)\n",
    "        elif token in (',', ';', '(', ')'):\n",
    "            yield (token, TokenType.PUNCTUATION)\n",
    "        elif token.upper() in SQL_KEYWORDS:\n",
    "            yield (token.upper(), SQL_KEYWORDS[token.upper()])\n",
    "        elif re.match(r'^[\\'\"].*[\\'\"]$', token):\n",
    "            yield (token, TokenType.STRING)\n",
    "        elif re.match(r'^\\d+(\\.\\d+)?$', token):\n",
    "            yield (token, TokenType.NUMBER)\n",
    "        elif re.match(r'<=|>=|<>|!=|<|>|=$', token):\n",
    "            yield (token, TokenType.OPERATOR)\n",
    "        else:\n",
    "            yield (token, TokenType.IDENTIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ad6b1-aa48-4c51-95b8-84ffa93a7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "sql_query_test_01 = \"SELECT name, age FROM users WHERE age >= 21 AND status = 'active' ORDER BY age DESC;\"\n",
    "t = tokenize(sql_query_test_01)\n",
    "print(list(t))\n",
    "# next(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718944e3-0a01-42d3-9252-75541c281666",
   "metadata": {},
   "source": [
    "## AST Node Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141020d-53b1-4c47-949c-50fc46ddf85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTNode:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6752a17-ea28-49fd-a6b1-2aa3e255b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectStatement(ASTNode):\n",
    "    def __init__(self, columns, table_name, where_clause=None):\n",
    "        self.columns = columns  # List of column names or '*'\n",
    "        self.table_name = table_name  # Name of the table\n",
    "        self.where_clause = where_clause  # WhereClause node or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea9efe-b544-41a1-8260-31ebb7264348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhereClause(ASTNode):\n",
    "    def __init__(self, condition):\n",
    "        self.condition = condition  # This could be a more complex structure in a full implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d76103-fd3e-4956-928e-5e7be79b3908",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a87569-0998-407c-8a55-62adc1a340f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(expression):\n",
    "    token_specification = [\n",
    "        ('NUMBER',   r'\\d+(\\.\\d*)?'),  # Integer or decimal number\n",
    "        ('PLUS',     r'\\+'),           # Addition operator\n",
    "        ('MULT',     r'\\*'),           # Multiplication operator\n",
    "        ('WS',       r'\\s+'),          # Whitespace\n",
    "    ]\n",
    "    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n",
    "    for mo in re.finditer(tok_regex, expression):\n",
    "        kind = mo.lastgroup\n",
    "        value = mo.group()\n",
    "        if kind != 'WS':  # Ignore whitespace\n",
    "            yield (kind, value)\n",
    "\n",
    "# Example usage\n",
    "tokens = tokenize(\"3 + 5 * 2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea30a36-d302-4642-8327-a48d227bea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = iter(tokens)\n",
    "        self.current_token = None\n",
    "        self.next_token()\n",
    "    \n",
    "    def next_token(self):\n",
    "        try:\n",
    "            self.current_token = next(self.tokens)\n",
    "        except StopIteration:\n",
    "            self.current_token = None\n",
    "\n",
    "    def parse_expression(self):\n",
    "        \"\"\"Expression ::= Term ((PLUS) Term)*\"\"\"\n",
    "        value = self.parse_term()\n",
    "        while self.current_token and self.current_token[0] == 'PLUS':\n",
    "            self.next_token()\n",
    "            value += self.parse_term()\n",
    "        return value\n",
    "\n",
    "    def parse_term(self):\n",
    "        \"\"\"Term ::= Factor ((MULT) Factor)*\"\"\"\n",
    "        value = self.parse_factor()\n",
    "        while self.current_token and self.current_token[0] == 'MULT':\n",
    "            self.next_token()\n",
    "            value *= self.parse_factor()\n",
    "        return value\n",
    "\n",
    "    def parse_factor(self):\n",
    "        \"\"\"Factor ::= NUMBER\"\"\"\n",
    "        if self.current_token and self.current_token[0] == 'NUMBER':\n",
    "            value = float(self.current_token[1])\n",
    "            self.next_token()\n",
    "            return value\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER')\n",
    "\n",
    "# Example usage\n",
    "tokens = tokenize(\"3 + 5 * 2\")\n",
    "parser = Parser(tokens)\n",
    "result = parser.parse_expression()\n",
    "print(result)  # Output: 13.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbbfb78-528e-46c9-bd26-754f39b33ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "sql_query_test_02 = \"SELECT name, age FROM users WHERE age > 30\"\n",
    "# print(\"SQL Query:\\n\\t\", sql_query_test_02)\n",
    "tokens = tokenize(sql_query_test_02)\n",
    "print(\"Tokenized:\\n\\t\",list(tokens), \" \", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025da134-613e-46cc-b7fb-d5389d30ff56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Parser:\n",
    "\tdef __init__(self, tokens):\n",
    "\t\tself.tokens = tokens\n",
    "\t\tprint(\"Parser:__init__: tokens = \",type(tokens))\n",
    "\t\tprint(\"Parser:__init__: dir(tokens) = \",dir(tokens))\n",
    "\t\tprint(\"Parser:__init__: tokens = \",list(tokens))\n",
    "\t\tself.current_token = None\n",
    "\t\tprint(\"Parser:__init__: self.current_token = \",self.current_token)\n",
    "\t\tself.next_token = None\n",
    "\t\tself._next_token()\n",
    "\n",
    "\tdef _next_token(self):\n",
    "\t\t\"\"\"Advance to the next token.\"\"\"\n",
    "\t\tprint(\"Parser:_advance: self.current_token = \",self.current_token)\n",
    "\t\ttry:\n",
    "\t\t\tself.current_token = self.next_token\n",
    "\t\t\tself.next_token = next(self.tokens, None)\n",
    "\t\texcept StopIteration:\n",
    "\t\t\tself.current_token = None\n",
    "\t\t# if self.current_token == None:\n",
    "\t\t# \tself.current_token = next(self.tokens, None)\n",
    "\t\t# self.current_token = self.next_token\n",
    "\t\t# self.next_token = next(self.tokens, None)\n",
    "\n",
    "\tdef parse(self):\n",
    "\t\t\"\"\"Parse the tokens into an AST.\"\"\"\n",
    "\t\tprint(\"Parse:parse, self.current_token = \", self.current_token)\n",
    "\t\tprint(\"Parse:parse, dir(self.current_token) = \", dir(self.current_token))\n",
    "\t\tif self.current_token.type != TokenType.SELECT:\n",
    "\t\t\traise SyntaxError(\"Query must start with SELECT\")\n",
    "\t\tself._advance()\n",
    "\n",
    "\t\tcolumns = self._parse_columns()\n",
    "\n",
    "\t\tif self.current_token.type != TokenType.FROM:\n",
    "\t\t\traise SyntaxError(\"Expected FROM after column list\")\n",
    "\t\tself._advance()\n",
    "\n",
    "\t\ttable_name = self._parse_table_name()\n",
    "\n",
    "\t\twhere_clause = None\n",
    "\t\tif self.current_token.type == TokenType.WHERE:\n",
    "\t\t\tself._advance()\n",
    "\t\t\twhere_clause = self._parse_where_clause()\n",
    "\n",
    "\t\treturn SelectStatement(columns, table_name, where_clause)\n",
    "\n",
    "\tdef _parse_columns(self):\n",
    "\t\t\"\"\"Parse the columns part of the SELECT statement.\"\"\"\n",
    "\t\tcolumns = []\n",
    "\t\tif self.current_token.type == TokenType.ASTERISK:\n",
    "\t\t\tcolumns.append('*')\n",
    "\t\t\tself._advance()\n",
    "\t\telse:\n",
    "\t\t\twhile True:\n",
    "\t\t\t\tif self.current_token.type != TokenType.IDENTIFIER:\n",
    "\t\t\t\t\traise SyntaxError(\"Expected column name\")\n",
    "\t\t\t\tcolumns.append(self.current_token.value)\n",
    "\t\t\t\tself._advance()\n",
    "\n",
    "\t\t\t\tif self.current_token.type != TokenType.COMMA:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tself._advance()  # Skip the comma\n",
    "\n",
    "\t\treturn columns\n",
    "\n",
    "\tdef _parse_table_name(self):\n",
    "\t\t\"\"\"Parse the table name.\"\"\"\n",
    "\t\tif self.current_token.type != TokenType.IDENTIFIER:\n",
    "\t\t\traise SyntaxError(\"Expected table name\")\n",
    "\t\ttable_name = self.current_token.value\n",
    "\t\tself._advance()\n",
    "\t\treturn table_name\n",
    "\n",
    "\tdef _parse_where_clause(self):\n",
    "\t\t\"\"\"Parse the WHERE clause.\"\"\"\n",
    "\t\t# In a full implementation, this would need to handle complex expressions.\n",
    "\t\t# For simplicity, we'll assume it's just a single condition.\n",
    "\t\tif self.current_token.type != TokenType.IDENTIFIER:\n",
    "\t\t\traise SyntaxError(\"Expected condition after WHERE\")\n",
    "\t\tcondition = self.current_token.value\n",
    "\t\tself._advance()\n",
    "\t\treturn WhereClause(condition)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed39293-28dd-471b-b9cc-9a8fd28cedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser(tokens)\n",
    "# print(\"Parser:\\n\\t\",tokens)\n",
    "ast = parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355676a-5cc4-40c3-8a92-d166e1f66140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the AST for demonstration\n",
    "print(ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81ca85-717b-4a35-8894-cac73dd6dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(eval_expr,sample_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b0989-597e-4fe1-a0e5-b6190ce27f1d",
   "metadata": {},
   "source": [
    "**A note of caution:**   \n",
    "eval() and exec() built-in methods in Python are considered problematic from a Security standpoint as they let one run arbitrary code.\n",
    "We'll see later how to implement a safer version.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b30f15-73e1-47a3-a4d5-37ee9b0a0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what would our simple query look like?\n",
    "# let's say something that get's us movies with a specific Id?\n",
    "table_metadata = {\n",
    "\t'name': 'movies',\n",
    "\t'columns': ['movieId', 'title', 'genres']\n",
    "}\n",
    "\n",
    "where_clause = 'int(movieId) == 12'\n",
    "\n",
    "a_simple_query = where_clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea16e1-244f-4a8d-b1dd-0b4c64420bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a SELECT query given a dictionary with data in it\n",
    "def execute_select(query, table_data):\n",
    "\tcolumns = table_metadata['columns']\n",
    "\ttable_name = table_metadata['name']\n",
    "\twhere_clause = query\n",
    "\tselected_rows = []\n",
    "\t# SELECT * FROM\n",
    "\tdata = table_data[table_name]\n",
    "\tfor row in data:\n",
    "\t\tif where_clause:\n",
    "\t\t\t# Apply WHERE clause filtering\n",
    "\t\t\tif eval(where_clause, row):\n",
    "\t\t\t\tselected_rows.append({col: row[col] for col in columns})\n",
    "\t\telse:\n",
    "\t\t\tselected_rows.append({col: row[col] for col in columns})\n",
    "\treturn selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90ad76-3592-4ed7-8c9f-fc67b94648d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = execute_select(a_simple_query, movies_data)\n",
    "print('result: \\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0f8c9-c482-4b15-83de-62f70dd39d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_query = 'int(movieId) <= 12'\n",
    "result = execute_select(another_query, movies_data)\n",
    "print('result: \\n', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77dde7-b426-4a2b-a247-547b8c572f7b",
   "metadata": {},
   "source": [
    "Wait, was it this simple?   \n",
    "Yea!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd9648-5a13-446f-a775-76616ace03c1",
   "metadata": {},
   "source": [
    "# Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f9979-d5c1-4fa6-875d-76e2c017ec76",
   "metadata": {},
   "source": [
    "Building a more feature rich data engine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
